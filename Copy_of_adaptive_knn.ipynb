{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/holly-hewitt/ML-Practical-Coursework/blob/main/Copy_of_adaptive_knn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coursework 2 (Practical) for COMPSCI4061 / COMPSCI5014 Machine Learning H / M - 2023-24\n",
        "\n",
        "### Problem Statement\n",
        "\n",
        "The explicit task description for this assignment is at the bottom of this notebook.\n",
        "\n",
        "In this assignment, we are going to explore an adaptive K-NN classifier. Usually, for K-NN classification (which is a non-parametric approach), we work with a fixed value of $k$. After storing the data instances and the labels, during the inference time for each point, we get its $k$-neighborhood and predict the majority label from its neighborhood as the label of the current point.\n",
        "\n",
        "In this report, we are going to investigate if a variable $k$ (the value of which depends on the data instance) performs better than a static choice of $k$.\n",
        "\n",
        "We are going to implement two different approaches - one based on heuristics, and the other based on a supervised parametric classifier that predicts the value of $k$ given a data instance."
      ],
      "metadata": {
        "id": "9as8OW5--yyp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following block of code downloads and prepares the dataset to be used. It also shows some sample images from the training set."
      ],
      "metadata": {
        "id": "jkG2Tt2q_ALd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import random\n",
        "\n",
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "\n",
        "from matplotlib import pyplot\n",
        "for i in range(9):\n",
        "  pyplot.subplot(330 + 1 + i)\n",
        "  pyplot.imshow(x_train[i], cmap=pyplot.get_cmap('gray'))\n",
        "\n",
        "pyplot.show()\n",
        "\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 784)\n",
        "x_test = x_test.reshape(x_test.shape[0], 784)\n",
        "y_train = y_train.reshape(y_train.shape[0], 1)\n",
        "y_test = y_test.reshape(y_test.shape[0], 1)\n",
        "\n",
        "NUM_TRAIN_SAMPLES = x_train.shape[0]\n",
        "NUM_TEST_SAMPLES = x_test.shape[0]\n",
        "\n",
        "print(\"Train samples: {} {}\".format(x_train.shape, y_train.shape))\n",
        "print(\"Test samples: {} {}\".format(x_test.shape, y_test.shape))\n",
        "\n",
        "# We conduct all the evaluation on a *small subset* of the test data\n",
        "EVAL_SUBSET_SIZE = 100\n",
        "eval_ids = np.random.randint(NUM_TEST_SAMPLES, size=EVAL_SUBSET_SIZE)\n",
        "x_test = x_test[eval_ids,:]\n",
        "y_test = y_test[eval_ids,:]\n",
        "\n",
        "print(\"Evaluation set: {}\".format(x_test.shape))\n",
        "\n",
        "NUM_TRAIN_SAMPLES = x_train.shape[0]\n",
        "NUM_TEST_SAMPLES = x_test.shape[0]\n",
        "y_train = y_train.ravel()\n",
        "y_test = y_test.ravel()\n",
        "\n",
        "print(\"Train samples: {} {}\".format(x_train.shape, y_train.shape))\n",
        "print(\"Test samples: {} {}\".format(x_test.shape, y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "s5WQjSG5-rvo",
        "outputId": "f48d946b-d45c-468f-dabd-872b9a443aaf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 9 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAGgCAYAAABCAKXYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5X0lEQVR4nO3df1xUdb7H8Q8YjL9gCAuQK6NUlpabbQSI+jArknTLTLe2bmVWV1LBIndr17Iy+8Hm7raWP3K3ErJydd1W3WyzvOCPtdCCe93HJZK11lW6ypi7MYOooHLuHz2ay/coA8PMcH7M6/l4nMfjvOfMjy8zH/hy5nvO90RpmqYJAACwpWijGwAAAMKHjh4AABujowcAwMbo6AEAsDE6egAAbIyOHgAAG6OjBwDAxujoAQCwMTp6AABsjI4eAAAbC1tHv3TpUhk0aJD07NlTsrOz5ZNPPgnXSwEhRe3CqqhdnE1UOOa6X7NmjUydOlWWL18u2dnZsmjRIlm7dq3U1tZKUlKS38e2trbKwYMHJS4uTqKiokLdNISBpmnS2NgoqampEh1t7S+JqN3IQu1+i9q1noBqVwuDrKwsraCgwJdPnz6tpaamasXFxR0+tq6uThMRFgsudXV14SinbkXtRuZC7VK7Vl06U7sh/xe2paVFqqqqJDc313dbdHS05ObmSkVFxRn3b25uFq/X61s0LqZnWXFxcUY3ISjUbuSidqldq+pM7Ya8oz9y5IicPn1akpOTlduTk5Olvr7+jPsXFxeL0+n0LS6XK9RNQjex+ld+1G7konapXavqTO0aPig1d+5c8Xg8vqWurs7oJgGdQu3CqqjdyHJOqJ/wvPPOkx49eojb7VZud7vdkpKScsb9HQ6HOByOUDcDCBi1C6uiduFPyPfoY2NjJSMjQ8rKyny3tba2SllZmeTk5IT65YCQoXZhVdQu/Or6MZ7tW716teZwOLTS0lKtpqZGy8/P1xISErT6+voOH+vxeAw/ipGla4vH4wlHOXUrajcyF2qX2rXq0pnaDUtHr2matnjxYs3lcmmxsbFaVlaWtnPnzk49joKz7mKHP5aaRu1G4kLtUrtWXTpTu2GZMCcYXq9XnE6n0c1AF3g8HomPjze6GYahdq2L2qV2raoztWv4UfcAACB86OgBALAxOnoAAGyMjh4AABujowcAwMbo6AEAsLGQT4ELwP4yMjKUXFhYqOSpU6cqeeXKlUpevHixkv/rv/4rhK0D0BZ79AAA2BgdPQAANsZX9yHWo0cPJQcy25T+68/evXsr+ZJLLlFyQUGBkn/5y18q+Y477lDyiRMnlPzzn//ct/700093up2IPFdccYWSN2/erGT9zFz6CTfvvvtuJU+cOFHJ/fr1C7KFgDGuu+46Jb/99ttKvvrqq5VcW1sb9jbpsUcPAICN0dEDAGBjdPQAANgYY/Q6LpdLybGxsUoeOXKkkkePHq3khIQEJU+ZMiVkbfvqq6+U/PLLLyv5lltuUXJjY6OS//rXvyp527ZtIWsb7CcrK8u3/s477yjb9Mee6Mfk9bXX0tKiZP2Y/IgRI5SsP91O/3iYz5gxY3zr+s933bp13d2cbpOZmankTz/91KCWtI89egAAbIyOHgAAG6OjBwDAxiJ+jF5/fnB5ebmSAzkPPtRaW1uVPG/ePCUfPXpUyfrzNw8dOqTkb775RslGnM8J89DP03DllVcq+a233vKt9+/fP6Dn3rt3r5IXLlyo5NWrVyv5o48+UrK+1ouLiwN6fXS/sWPH+tYHDx6sbLPTGH10tLp/nJ6eruSBAwcqOSoqKuxt6gh79AAA2BgdPQAANkZHDwCAjUX8GP2BAweU/M9//lPJoRyj37Vrl5IbGhqUfM011yhZf+7wm2++GbK2AL/5zW+UrL82QjD04/19+/ZVsn4Oh7bjuyIil19+ecjagu7R9tLEFRUVBrYkvPTHq0yfPl3JbY9tERHZs2dP2NvUEfboAQCwMTp6AABsjI4eAAAbi/gx+n/9619KfuSRR5R84403Kvm///u/layfb15v9+7dvvXrr79e2dbU1KTkyy67TMkPPfSQ3+cGApGRkaHkH/zgB0r2d76vfkz93XffVfIvf/lLJR88eFDJ+t8b/ZwO1157bafbAnPSn19uV6+99prf7fo5JMwgMj4ZAAAiFB09AAA2FnBHv337drnpppskNTVVoqKiZP369cp2TdPkySeflP79+0uvXr0kNzfXlF9lIPJQu7AqahfBCHiMvqmpSYYPHy733XefTJ48+YztCxculJdfflneeOMNSU9PlyeeeELy8vKkpqZGevbsGZJGh5P+F0g/973+OtvDhw9X8v3336/ktmOX+jF5vc8++0zJ+fn5fu+PwNi9dvX013HYvHmzkuPj45Wsv6b8+++/71vXn2N/9dVXK1k/N71+HPPrr79W8l//+lcl66/roD9+QH9evv569XZnxtrVz3WQnJwcltcxm47mVtH/nplBwB39+PHjZfz48WfdpmmaLFq0SObNmyc333yziIisXLlSkpOTZf369XL77bef8Zjm5mZpbm72Za/XG2iTgE6hdmFV1C6CEdIx+n379kl9fb3k5ub6bnM6nZKdnd3uTEnFxcXidDp9S1paWiibBHQKtQuronbRkZB29PX19SJy5lc4ycnJvm16c+fOFY/H41vq6upC2SSgU6hdWBW1i44Yfh69w+EQh8NhdDPa1dFXWh6Px+/2tvMgr1mzRtmmH5eEtZitdi+++GIl6+eE0I8tHjlyRMmHDh1S8htvvOFbP3r0qLLtvffe85uD1atXLyX/+Mc/VvKdd94Z0teLNKGo3QkTJihZ/5nZhf4fKP315/X+93//N5zN6ZKQ7tGnpKSIiIjb7VZud7vdvm2AGVG7sCpqFx0JaUefnp4uKSkpUlZW5rvN6/XKrl27JCcnJ5QvBYQUtQuronbRkYC/uj969Kh88cUXvrxv3z7ZvXu3JCYmisvlkqKiInn22Wdl8ODBvtM8UlNTZdKkSaFsNxAwahdWRe0iGAF39JWVlcp10+fMmSMiIvfcc4+UlpbKo48+Kk1NTZKfny8NDQ0yevRo2bRpkyXPQ+6M+fPnK1k/n3jb843bHhUrIvLhhx+GrV04k91qVz/Gqp9vXj+Gqp8Dou31w0W+fX/aMtOYq8vlMroJhjJj7V5yySXtbtPPCWJl+t8r/Zj93/72NyXrf8/MIOCOfuzYsWdMrNFWVFSULFiwQBYsWBBUw4BQo3ZhVdQugsFc9wAA2BgdPQAANmb4efRWp5+/vu158yLqnNyvvvqqsm3Lli1K1o+RLl26VMn+vrpD5Pn+97+vZP2YvN5306N+R3+NeSBUPv30U6Ob0C79NR5uuOEGJd91111KHjdunN/ne+aZZ5Tc0NDQ9caFCXv0AADYGB09AAA2xlf3Ifbll18qedq0ab71kpISZdvdd9/tN/fp00fJK1euVLJ+ylJElhdffFHJUVFRStZ/NW/mr+qjo9V9DqaHtrbExMSgHq+//Le+tvWnKg8YMEDJsbGxvnX9dMn6Wjt+/LiSd+3apeS2V/kTETnnHLXbrKqqErNjjx4AABujowcAwMbo6AEAsDHG6MNs3bp1vvW9e/cq2/RjrNddd52Sn3/+eSUPHDhQyc8995ySzXh5RITOjTfeqOQrrrhCyfrTL//0pz+Fu0khox+T1/8su3fv7sbWoDP0Y9ttP7Ply5cr2x577LGAnvvyyy9Xsn6M/tSpU0o+duyYkmtqanzrK1asULbpT2PWH7uivwrgV199pWT91NB79uwRs2OPHgAAG6OjBwDAxujoAQCwMcbou1F1dbWSb7vtNiXfdNNNStafd//AAw8oefDgwUq+/vrrg20iTEw/Ntj2XGERkcOHDyt5zZo1YW9TZ+kvqau/vLNeeXm5kufOnRvqJiFIs2bNUvL+/ft96yNHjgzquQ8cOKDk9evXK/nzzz9X8s6dO4N6vbby8/OVfP755yv573//e8heq7uwRw8AgI3R0QMAYGN09AAA2Bhj9AbSX87wzTffVPJrr72mZP0cy2PGjFHy2LFjlbx169ag2gdr0c/JbeS1EPRj8vPmzVPyI488omT9ucq/+tWvlHz06NEQtg7h8MILLxjdhJDQz2ei984773RTS0KHPXoAAGyMjh4AABujowcAwMYYo+9G+vmbf/jDHyo5MzNTyfoxeb228zmLiGzfvj2I1sHqjJzbXj/vvn4M/kc/+pGSN2zYoOQpU6aEpV1AqLW9folVsEcPAICN0dEDAGBjdPQAANgYY/Qhdskllyi5sLDQtz558mRlW0pKSkDPffr0aSXrz5PWX9Mb9qK/Jrc+T5o0SckPPfRQ2Nry8MMPK/mJJ55QstPpVPLbb7+t5KlTp4anYQDOwB49AAA2RkcPAICNBdTRFxcXS2ZmpsTFxUlSUpJMmjRJamtrlfucOHFCCgoKpF+/ftK3b1+ZMmWKuN3ukDYaCBS1C6uidhGsgMbot23bJgUFBZKZmSmnTp2Sxx57TMaNGyc1NTXSp08fEfl27O69996TtWvXitPplMLCQpk8ebJ89NFHYfkBupt+XP2OO+5QctsxeRGRQYMGdfm1Kisrlfzcc88p2cjzpq3GDrWraZrfrK/Nl19+WckrVqxQ8j//+U8ljxgxQsl33323b3348OHKtgEDBihZf/3wDz74QMnLli0TdI0datfK9MfCXHzxxUreuXNndzanSwLq6Ddt2qTk0tJSSUpKkqqqKhkzZox4PB55/fXXZdWqVXLttdeKiEhJSYkMHTpUdu7cecYfEpFvL8TR9mIcXq+3Kz8H4Be1C6uidhGsoMboPR6PiIgkJiaKiEhVVZWcPHlScnNzffcZMmSIuFwuqaioOOtzFBcXi9Pp9C1paWnBNAnoFGoXVkXtIlBd7uhbW1ulqKhIRo0aJcOGDRMRkfr6eomNjZWEhATlvsnJyVJfX3/W55k7d654PB7fUldX19UmAZ1C7cKqqF10RZfPoy8oKJDq6mrZsWNHUA1wOBxnXLvaSMnJyUq+9NJLlbxkyRIlDxkypMuvtWvXLiX/4he/ULJ+PnDOkw8Nu9Zujx49lDxr1iwl6+eT139dO3jw4E6/1scff6zkLVu2KPnJJ5/s9HOh8+xau2amPxYmOtp6J6t1qcWFhYWyceNG2bJli3JQTkpKirS0tEhDQ4Nyf7fbHfDkMEA4ULuwKmoXXRVQR69pmhQWFsq6deukvLxc0tPTle0ZGRkSExMjZWVlvttqa2vlwIEDkpOTE5oWA11A7cKqqF0EK6Cv7gsKCmTVqlWyYcMGiYuL843/OJ1O6dWrlzidTrn//vtlzpw5kpiYKPHx8TJ79mzJyck565GfQHehdmFV1C6CFaXpByD83Vl3PuF3SkpKZNq0aSLy7cQNP/7xj+V3v/udNDc3S15enixbtqzTXyF5vd4z5skOpe+OVP3Ob37zGyXrr6t9wQUXBPV6bccyf/WrXynb9OcaHz9+PKjXMprH45H4+Hijm3FWdqhd/bnra9euVXJmZqbfx+vfg45+9dueZ7969WplWzjn0TcCtRve2rWSNWvWKPnWW29V8quvvqrkBx54IOxt8qcztRvQHn1n/ifo2bOnLF26VJYuXRrIUwNhRe3CqqhdBMt6hw8CAIBOo6MHAMDGbHk9+uzsbN/6I488omzLyspS8r/9278F9VrHjh1Tsn5+8eeff9633tTUFNRrIbJ99dVXSp48ebKS9WOF8+bNC+j5X3rpJSW/8sorvvUvvvgioOcC7KK9YySshD16AABsjI4eAAAbs+VX97fccstZ1zujpqZGyRs3blTyqVOnlKw/ZU4/OxUQLocOHVLy/Pnz/WYAHXv//feVrD+9zorYowcAwMbo6AEAsDE6egAAbCygKXC7A1MxWpeZpxHtDtSudVG71K5VdaZ22aMHAMDG6OgBALAxOnoAAGyMjh4AABujowcAwMbo6AEAsDE6egAAbIyOHgAAG6OjBwDAxujoAQCwMdN19CabkRcBiPTPLtJ/fiuL9M8u0n9+K+vMZ2e6jr6xsdHoJqCLIv2zi/Sf38oi/bOL9J/fyjrz2Znuojatra1y8OBB0TRNXC6X1NXVRfTFJgLl9XolLS2tW983TdOksbFRUlNTJTradP87dhtqNzjUrnGo3eCYvXbP6ZYWBSA6OloGDBggXq9XRETi4+MpuC7o7veNK19Ru6FC7XY/ajc0zFq7kfsvLAAAEYCOHgAAGzNtR+9wOOSpp54Sh8NhdFMshffNeHwGXcP7Zjw+g64x+/tmuoPxAABA6Jh2jx4AAASPjh4AABujowcAwMbo6AEAsDE6egAAbMy0Hf3SpUtl0KBB0rNnT8nOzpZPPvnE6CaZRnFxsWRmZkpcXJwkJSXJpEmTpLa2VrnPiRMnpKCgQPr16yd9+/aVKVOmiNvtNqjFkYXabR+1a27UbvssXbuaCa1evVqLjY3VVqxYoX322Wfa9OnTtYSEBM3tdhvdNFPIy8vTSkpKtOrqam337t3ahAkTNJfLpR09etR3nxkzZmhpaWlaWVmZVllZqY0YMUIbOXKkga2ODNSuf9SueVG7/lm5dk3Z0WdlZWkFBQW+fPr0aS01NVUrLi42sFXmdfjwYU1EtG3btmmapmkNDQ1aTEyMtnbtWt99Pv/8c01EtIqKCqOaGRGo3cBQu+ZB7QbGSrVruq/uW1papKqqSnJzc323RUdHS25urlRUVBjYMvPyeDwiIpKYmCgiIlVVVXLy5EnlPRwyZIi4XC7ewzCidgNH7ZoDtRs4K9Wu6Tr6I0eOyOnTpyU5OVm5PTk5Werr6w1qlXm1trZKUVGRjBo1SoYNGyYiIvX19RIbGysJCQnKfXkPw4vaDQy1ax7UbmCsVrumu0wtAlNQUCDV1dWyY8cOo5sCBITahVVZrXZNt0d/3nnnSY8ePc44UtHtdktKSopBrTKnwsJC2bhxo2zZskUGDBjguz0lJUVaWlqkoaFBuT/vYXhRu51H7ZoLtdt5Vqxd03X0sbGxkpGRIWVlZb7bWltbpaysTHJycgxsmXlomiaFhYWybt06KS8vl/T0dGV7RkaGxMTEKO9hbW2tHDhwgPcwjKjdjlG75kTtdszStRuuo/yWLFmiDRw4UHM4HFpWVpa2a9euTj929erVmsPh0EpLS7WamhotPz9fS0hI0Orr68PVXEuZOXOm5nQ6ta1bt2qHDh3yLceOHfPdZ8aMGZrL5dLKy8u1yspKLScnR8vJyTGw1dZB7YYPtRte1G74WLl2w3KZ2jVr1sjUqVNl+fLlkp2dLYsWLZK1a9dKbW2tJCUl+X1sa2urHDx4UFatWiWLFy8Wt9stl19+uSxcuFCuuuqqUDfVkpxO51lvX7Zsmdx5550i8u3EDY8//rj84Q9/kObmZrnuuuvkxRdfPONgm1DQNE0aGxslNTVVoqNN9yVRQKjd8KJ2w4faDS9L1244/nsI5nzMuro6TURYLLjU1dWFo5y6FbUbmQu1S+1adelM7Yb8X9hAz8dsbm4Wr9frW7TQf8GAbhIXF2d0E4JC7UYuapfatarO1G7IO/pAz8csLi4Wp9PpW1wuV6ibhG4SFRVldBOCQu1GLmqX2rWqztSu4YNSc+fOFY/H41vq6uqMbhLQKdQurIrajSwhnzAn0PMxHQ6HOByOUDcDCBi1C6uiduFPyPfoOR8TVkXtwqqoXfjV9WM82xfM+Zgej8fwoxhZurZ4PJ5wlFO3onYjc6F2qV2rLp2p3bBNmLN48WLN5XJpsbGxWlZWlrZz585OPY6Cs+5ihz+WmkbtRuJC7VK7Vl06U7thmTAnGF6vt92JCWBuHo9H4uPjjW6GYahd66J2qV2r6kztGn7UPQAACB86egAAbIyOHgAAG6OjBwDAxujoAQCwMTp6AABsjI4eAAAbo6MHAMDG6OgBALAxOnoAAGws5JepRfjMmzdPyU8//bSSo6PV/9vGjh2r5G3btoWlXQBgFXFxcUru27evkn/wgx8o+fzzz1fyiy++qOTm5uYQti482KMHAMDG6OgBALAxOnoAAGyMMXoTmzZtmpJ/+tOfKrm1tdXv4012BWIA6BaDBg3yrev/bubk5Ch52LBhAT13//79lfzggw8G1jgDsEcPAICN0dEDAGBjdPQAANgYY/QmNnDgQCX37NnToJYgEmRnZyv5rrvu8q1fffXVyrbLLrvM73P95Cc/UfLBgweVPHr0aCW/9dZbSt61a5f/xiKiDRkyRMlFRUVKvvPOO33rvXr1UrZFRUUpua6uTsmNjY1KHjp0qJJvu+02JS9btkzJe/bsaafVxmGPHgAAG6OjBwDAxujoAQCwMcboTSQ3N1fJs2fP9nt//VjQjTfeqGS32x2ahsGWfvSjHyn5pZdeUvJ5553nW9ePa27dulXJ+vnAf/GLX/h9bf3z6R9/++23+3087M3pdCr5hRdeULK+dvXz1/uzd+9eJefl5Sk5JiZGyfq/s21/L86WzYg9egAAbIyOHgAAG6OjBwDAxhijN5D+XOKSkhIl68ep9PTjoPv37w9Nw2AL55yj/npfddVVSn711VeV3Lt3byVv377dt/7MM88o23bs2KFkh8Oh5N///vdKHjdunN+2VlZW+t2OyHLLLbco+T/+4z+6/Fxffvmlkq+//nol68+jv+iii7r8WmbFHj0AADYWcEe/fft2uemmmyQ1NVWioqJk/fr1ynZN0+TJJ5+U/v37S69evSQ3N/eMoxwBI1C7sCpqF8EIuKNvamqS4cOHy9KlS8+6feHChfLyyy/L8uXLZdeuXdKnTx/Jy8uTEydOBN1YIBjULqyK2kUwAh6jHz9+vIwfP/6s2zRNk0WLFsm8efPk5ptvFhGRlStXSnJysqxfv55zY3XuueceJaempvq9v/7c5ZUrV4a6SbYWabXbdq56EZHXXnvN7/03b96s5LbnKnu9Xr+P1Z/X3NGY/FdffaXkN954w+/9I12k1e6tt94a0P3/8Y9/KPnTTz/1reuvR68fk9fTz21vByEdo9+3b5/U19crE784nU7Jzs6WioqKsz6mublZvF6vsgDdjdqFVVG76EhIO/r6+noREUlOTlZuT05O9m3TKy4uFqfT6VvS0tJC2SSgU6hdWBW1i44YftT93LlzxePx+JaOvlYBzILahVVRu5ElpOfRp6SkiMi3c6z379/fd7vb7ZYrrrjirI9xOBxnnINrV/o5ke+77z4lt7a2KrmhoUHJzz77bFjaBXvUrv5c98cee0zJmqYpWX8d7Xnz5ik5kK9zH3/88U7fV0TkwQcfVPLXX38d0OPx/+xQu3rTp09Xcn5+vpI//PBDJX/xxRdKPnz4cJdfW//NiB2EdI8+PT1dUlJSpKyszHeb1+uVXbt2SU5OTihfCggpahdWRe2iIwHv0R89elT572nfvn2ye/duSUxMFJfLJUVFRfLss8/K4MGDJT09XZ544glJTU2VSZMmhbLdQMCoXVgVtYtgBNzRV1ZWyjXXXOPLc+bMEZFvTxUrLS2VRx99VJqamiQ/P18aGhpk9OjRsmnTJunZs2foWg10AbULq6J2EYwoTT9wZzCv19vhHO9WMmjQIN/6O++8o2zTj5/px+j1Y64LFiwIadtCzePxSHx8vNHNMEx31+6TTz6p5KeeekrJLS0tSv7ggw+UfMcddyj5+PHj7b6WvsPQnyf/u9/9zu/99ceX6NtqNGrXXn93g/H6668rWT/fid7YsWOVrL8ORLh1pnYNP+oeAACEDx09AAA2RkcPAICNcT36MLvhhht865dffrnf+7Y9PUZE5KWXXgpLm2BNCQkJSp41a5aS9Yfb6MfkAz0Cu+11ud9++21lW0ZGht/H/uEPf1DywoULA3ptIBht52no06dPQI/93ve+53f7xx9/rOT2phk2E/boAQCwMTp6AABsjK/uQ0z/9ejPf/7zdu+rPw1DfxqHx+MJWbtgfbGxsUrWT6msp59mNikpScn33nuvkidOnKjkYcOG+db79u2rbNMPE+jzW2+9peSmpia/bQX86d27t5IvvfRSJetP15wwYUK7zxUdre7f6k9r1jt48KCS9b83p0+f9vt4M2CPHgAAG6OjBwDAxujoAQCwMcbog9R2iluRM6e59efvf/+7kt1udyiaBJvST2mrv7Tr+eefr+R9+/YpOdDZrtuOTeovWdv2cqgiIkeOHFHyu+++G9BrIbLFxMQo+fvf/76S9X9X9fWnn765be3qT39re8qzyJnj/3rnnKN2k5MnT1ay/jRo/e+pGbBHDwCAjdHRAwBgY3T0AADYGGP0QfrpT3+q5I7OyWzL3zn2gF5DQ4OS9XM2bNy4UcmJiYlK/vLLL5W8YcMGJZeWlir5X//6l2999erVyjb9GKl+O+CPfk4I/bj5H//4R7+Pf/rpp5VcXl6u5I8++si3rv890N+37XwRZ6M/9qW4uFjJBw4cUPL69euV3Nzc7Pf5uwN79AAA2BgdPQAANkZHDwCAjTFGH6ArrrhCyePGjev0Y/VjorW1taFoEiLUrl27lKwfSwzWmDFjfOtXX321sk1/LIp+TgigLf158vox9kceecTv499//30lL168WMn641fa/i78+c9/VrbpL0OrP+9df0ll/Rj+zTffrGT9JZz/8z//U8kvvPCCkr/55htpz+7du9vdFgz26AEAsDE6egAAbIyOHgAAG2OMPkAffvihks8991y/99+5c6dvfdq0aeFoEhAWvXr18q3rx+T18+ZzHj3a6tGjh5KfeeYZJf/kJz9RclNTk5J/9rOfKVlfX/ox+auuukrJS5Ys8a3r583fu3evkmfOnKnkLVu2KDk+Pl7JI0eOVPKdd96p5IkTJyp58+bN0p66ujolp6ent3vfYLBHDwCAjdHRAwBgY3T0AADYGGP0AerXr5+SO5rbftmyZb71o0ePhqVNQDh88MEHRjcBFpWfn69k/Zj8sWPHlPzAAw8oWX8s1IgRI5R87733Knn8+PFKbnt8yYIFC5RtJSUlStaPk+t5vV4lb9q0yW++4447lPzv//7v7T73ww8/7Pe1Q4U9egAAbCygjr64uFgyMzMlLi5OkpKSZNKkSWfM7nbixAkpKCiQfv36Sd++fWXKlCnidrtD2mggUNQurIraRbAC6ui3bdsmBQUFsnPnTtm8ebOcPHlSxo0bp5wa8fDDD8u7774ra9eulW3btsnBgwdl8uTJIW84EAhqF1ZF7SJYUZr+hNgAfP3115KUlCTbtm2TMWPGiMfjkfPPP19WrVolP/zhD0VEZM+ePTJ06FCpqKg4Y5zlbLxerzidzq42KeT04zn6c+E7GqO/4IILfOv79+8PWbvMyOPxnHHOqVlFQu0GKy8vz7euny9c/2dDf336r7/+OnwNCwNqN7S1e+jQISXrr8Ogv0b7nj17lNynTx8lX3TRRQG9/vz5833r+uvHnz59OqDnMrvO1G5QY/Qej0dERBITE0VEpKqqSk6ePCm5ubm++wwZMkRcLpdUVFSc9Tmam5vF6/UqCxBu1C6sitpFoLrc0be2tkpRUZGMGjXKd3Wf+vp6iY2NlYSEBOW+ycnJUl9ff9bnKS4uFqfT6VvS0tK62iSgU6hdWBW1i67ockdfUFAg1dXVQU99OXfuXPF4PL6lo1MdgGBRu7Aqahdd0aXz6AsLC2Xjxo2yfft2GTBggO/2lJQUaWlpkYaGBuW/S7fbLSkpKWd9LofDIQ6HoyvNCAv99ebbfh0mcuaYvP5axkuXLlUyR76ai51rN9TaHl8C41mpdvXfJOjH6PWvPXz4cL/Ppz9GZPv27Upev369kv/xj3/41u02Jt8VAe3Ra5omhYWFsm7dOikvLz9jAv6MjAyJiYmRsrIy3221tbVy4MABycnJCU2LgS6gdmFV1C6CFdAefUFBgaxatUo2bNggcXFxvv/anE6n9OrVS5xOp9x///0yZ84cSUxMlPj4eJk9e7bk5OR06shPIFyoXVgVtYtgBdTRv/LKKyIiMnbsWOX2kpIS32lnv/71ryU6OlqmTJkizc3NkpeXp0wDCxiB2oVVUbsIVlDn0YeD0eci63+Z9NcSjo5WRzv27dun5EDP97QTK52LHA5G126ofXdUt4jI//zP/yjb9Meq6MeCOY/eWkJdu3FxcUqeNGmSkq+88kolHz58WMkrVqxQ8jfffKNk/bFRkSzs59EDAABzo6MHAMDG6OgBALAxrkcP4Kyqq6t963v37lW26c+xv/DCC5VstTF6hFZjY6OS33zzTb8Z4cUePQAANkZHDwCAjfHVvY7+cokff/yxkkePHt2dzQFM4fnnn1fya6+9puTnnntOybNnz1ZyTU1NeBoGoEPs0QMAYGN09AAA2BgdPQAANsYUuAgZphG1b+3qP9ff//73StZfzvmPf/yjku+9914lNzU1hbB1waN27Vu7dscUuAAARDg6egAAbIyOHgAAG+M8egAd8nq9Sr7tttuUrD+PfubMmUqeP3++kjmvHug+7NEDAGBjdPQAANgYHT0AADbGefQIGc5Fpnatitqldq2K8+gBAIhwdPQAANiY6Tp6k40kIACR/tlF+s9vZZH+2UX6z29lnfnsTNfRNzY2Gt0EdFGkf3aR/vNbWaR/dpH+81tZZz470x2M19raKgcPHhRN08TlckldXV1EHyQTKK/XK2lpad36vmmaJo2NjZKamirR0ab737HbULvBoXaNQ+0Gx+y1a7qZ8aKjo2XAgAG+mbji4+MpuC7o7veNI3ap3VChdrsftRsaZq3dyP0XFgCACEBHDwCAjZm2o3c4HPLUU0+Jw+EwuimWwvtmPD6DruF9Mx6fQdeY/X0z3cF4AAAgdEy7Rw8AAIJHRw8AgI3R0QMAYGN09AAA2JhpO/qlS5fKoEGDpGfPnpKdnS2ffPKJ0U0yjeLiYsnMzJS4uDhJSkqSSZMmSW1trXKfEydOSEFBgfTr10/69u0rU6ZMEbfbbVCLIwu12z5q19yo3fZZunY1E1q9erUWGxurrVixQvvss8+06dOnawkJCZrb7Ta6aaaQl5enlZSUaNXV1dru3bu1CRMmaC6XSzt69KjvPjNmzNDS0tK0srIyrbKyUhsxYoQ2cuRIA1sdGahd/6hd86J2/bNy7Zqyo8/KytIKCgp8+fTp01pqaqpWXFxsYKvM6/Dhw5qIaNu2bdM0TdMaGhq0mJgYbe3atb77fP7555qIaBUVFUY1MyJQu4Ghds2D2g2MlWrXdF/dt7S0SFVVleTm5vpui46OltzcXKmoqDCwZebl8XhERCQxMVFERKqqquTkyZPKezhkyBBxuVy8h2FE7QaO2jUHajdwVqpd03X0R44ckdOnT0tycrJye3JystTX1xvUKvNqbW2VoqIiGTVqlAwbNkxEROrr6yU2NlYSEhKU+/Iehhe1Gxhq1zyo3cBYrXZNd/U6BKagoECqq6tlx44dRjcFCAi1C6uyWu2abo/+vPPOkx49epxxpKLb7ZaUlBSDWmVOhYWFsnHjRtmyZYsMGDDAd3tKSoq0tLRIQ0ODcn/ew/CidjuP2jUXarfzrFi7puvoY2NjJSMjQ8rKyny3tba2SllZmeTk5BjYMvPQNE0KCwtl3bp1Ul5eLunp6cr2jIwMiYmJUd7D2tpaOXDgAO9hGFG7HaN2zYna7Zila9fQQwHbsXr1as3hcGilpaVaTU2Nlp+fryUkJGj19fVGN80UZs6cqTmdTm3r1q3aoUOHfMuxY8d895kxY4bmcrm08vJyrbKyUsvJydFycnIMbHVkoHb9o3bNi9r1z8q1G7aOfsmSJdrAgQM1h8OhZWVlabt27Qro8YsXL9ZcLpcWGxurZWVlaTt37gxTS61HRM66lJSU+O5z/PhxbdasWdq5556r9e7dW7vlllu0Q4cOGddoC6F2w4faDS9qN3ysXLthuUztmjVrZOrUqbJ8+XLJzs6WRYsWydq1a6W2tlaSkpL8Pra1tVUOHjwocXFxEhUVFeqmIQw0TZPGxkZJTU2V6GjTjQYFhNqNLNTut6hd6wmodsPx30MwEy/U1dW1+58Ti7mXurq6cJRTt6J2I3Ohdqldqy6dqd2Q/wsb6MQLzc3N4vV6fYsW+i8Y0E3i4uKMbkJQqN3IRe1Su1bVmdoNeUcf6MQLxcXF4nQ6fYvL5Qp1k9BNrP6VH7UbuahdateqOlO7hg9KzZ07Vzwej2+pq6szuklAp1C7sCpqN7KEfGa8QCdecDgc4nA4Qt0MIGDULqyK2oU/Id+jZ+IFWBW1C6uiduFX14/xbF8wEy94PB7Dj2Jk6dri8XjCUU7ditqNzIXapXatunSmdsM2YU5XJ16g4Ky72OGPpaZRu5G4ULvUrlWXztRuWCbMCYbX6xWn02l0M9AFHo9H4uPjjW6GYahd66J2qV2r6kztGn7UPQAACB86egAAbIyOHgAAG6OjBwDAxujoAQCwMTp6AABsLORT4Ea6l156SckPPvigb726ulrZduONNyp5//794WsYACAisUcPAICN0dEDAGBjfHUfpEGDBin5rrvuUnJra6tvfejQocq2IUOGKJmv7tGdLr74YiXHxMQoecyYMb71ZcuWKdva1nUobNiwQcm33367kltaWkL6erAXfe2OHDnSt/78888r20aNGtUtbTIT9ugBALAxOnoAAGyMjh4AABtjjD5IX3/9tZK3b9+u5IkTJ3ZncwCfyy67TMnTpk1T8q233qrk6Gj1//7U1FTfun5MPtQXvdT/nixfvlzJRUVFSvZ6vSF9fVib/sp7W7Zs8a3X19cr21JSUpSs325H7NEDAGBjdPQAANgYHT0AADbGGH2QmpqalMy58DCL4uJiJU+YMMGglgRu6tSpSn799deV/NFHH3Vnc2Bh+jF5xugBAICt0NEDAGBjdPQAANgYY/RBSkhIUPLw4cONaQigs3nzZiV3NEZ/+PBhJbcdF9efY9/RXPdt5xoXEbn66qv93h8Il6ioKKObYDj26AEAsDE6egAAbIyOHgAAG2OMPki9e/dWssvl6vRjMzMzlbxnzx4lc04+gvHKK68oef369X7vf/LkSSUHc35xfHy8kqurq5Xcdh79s9G3tbKyssttQWTTX5ehZ8+eBrXEOOzRAwBgY3T0AADYWMAd/fbt2+Wmm26S1NRUiYqKOuMrNk3T5Mknn5T+/ftLr169JDc3V/bu3Ruq9gJdRu3CqqhdBCPgMfqmpiYZPny43HfffTJ58uQzti9cuFBefvlleeONNyQ9PV2eeOIJycvLk5qaGluOjRw8eFDJpaWlSp4/f367j9Vva2hoUPKSJUuCaBn0Iq12T506peS6urpue+28vDwln3vuuQE9/quvvlJyc3Nz0G2yskir3XC66qqrlLxz506DWtJ9Au7ox48fL+PHjz/rNk3TZNGiRTJv3jy5+eabRURk5cqVkpycLOvXr5fbb7/9jMc0Nzcrv8RerzfQJgGdQu3CqqhdBCOkY/T79u2T+vp6yc3N9d3mdDolOztbKioqzvqY4uJicTqdviUtLS2UTQI6hdqFVVG76EhIO/rvTsdJTk5Wbk9OTm73VJ25c+eKx+PxLd359SLwHWoXVkXtoiOGn0fvcDjE4XAY3YyQeeaZZ5Tsb4we1ma32g2G/uvh6dOnK7lXr14BPd+TTz4ZdJvQPrvVrv54FI/H41t3Op3KtgsvvLBb2mQmId2jT0lJERERt9ut3O52u33bADOidmFV1C46EtKOPj09XVJSUqSsrMx3m9frlV27dklOTk4oXwoIKWoXVkXtoiMBf3V/9OhR+eKLL3x53759snv3bklMTBSXyyVFRUXy7LPPyuDBg32neaSmpsqkSZNC2W4gYNQurIraRTAC7ugrKyvlmmuu8eU5c+aIiMg999wjpaWl8uijj0pTU5Pk5+dLQ0ODjB49WjZt2hSx53K2vY53R9fwRnhRu1135513KvlnP/uZki+66CIlx8TEBPT8u3fvVrJ+3v1IR+36p5+D5C9/+Ytv/cYbb+zm1phPwB392LFjz7hIQFtRUVGyYMECWbBgQVANA0KN2oVVUbsIBnPdAwBgY3T0AADYmOHn0dtd23F5f1+9AaE2aNAgJd99991KbjuTWkdGjx6t5EBrWT/Fqn6M/89//rOSjx8/HtDzA2gfe/QAANgYHT0AADbGV/eATQwbNkzJf/rTn5Tscrm6szmKtqc7iYj89re/NagliHT9+vUzugndjj16AABsjI4eAAAbo6MHAMDGGKMHbCoqKspvDkTbqZxFAp/OWT8N6fjx45X8/vvvd61hQIAmTpxodBO6HXv0AADYGB09AAA2RkcPAICNMUYfZoFcpnbMmDFKXrJkSVjaBHuqrq5W8tixY5V81113KfmDDz5Q8okTJ7r82vfff7+SZ8+e3eXnAoK1ZcsW3zqXqWWPHgAAW6OjBwDAxujoAQCwMcbowyyQy9ROnjxZyZdeeqmSa2pqQtcw2N7+/fuV/Nxzz4XttebPn69kxuhhpAMHDrS7LSYmRskDBw5Usv73xg7YowcAwMbo6AEAsDE6egAAbIwx+jBbvny5b/2BBx4I6LH5+flKLioqCkWTgJDLy8szugmAz6lTp9rdpr/mg8PhCHdzDMcePQAANkZHDwCAjdHRAwBgY4zRh9mePXuMbgJsQn/+77hx45RcXl6u5OPHj4etLffee6+SX3rppbC9FhCoDRs2+Nb1f4OHDBmiZP2xT7NmzQpbu4zCHj0AADZGRw8AgI0F1NEXFxdLZmamxMXFSVJSkkyaNElqa2uV+5w4cUIKCgqkX79+0rdvX5kyZYq43e6QNhoIFLULq6J2EaworaMJ2Nu44YYb5Pbbb5fMzEw5deqUPPbYY1JdXS01NTXSp08fERGZOXOmvPfee1JaWipOp1MKCwslOjpaPvroo069htfrFafT2bWfxuT+9re/KfnCCy/0e/+217IXEbnooouU/OWXX4amYSHi8XgkPj7e6GaclRVrd/To0Up+/PHHlXz99dcrOT09Xcl1dXVBvX5iYqJvfcKECcq2xYsXKzkuLs7vc+mPF5g4caKS214/3AjUrn3/7i5atEjJ+uNLkpOTlXzixIlwNymkOlO7AR2Mt2nTJiWXlpZKUlKSVFVVyZgxY8Tj8cjrr78uq1atkmuvvVZEREpKSmTo0KGyc+dOGTFixBnP2dzcLM3Nzb7s9XoDaRLQKdQurIraRbCCGqP3eDwi8v//+VdVVcnJkyclNzfXd58hQ4aIy+WSioqKsz5HcXGxOJ1O35KWlhZMk4BOoXZhVdQuAtXljr61tVWKiopk1KhRMmzYMBERqa+vl9jYWElISFDum5ycLPX19Wd9nrlz54rH4/EtwX7dCHSE2oVVUbvoii6fR19QUCDV1dWyY8eOoBrgcDgiYq5hEZHPPvtMyRdccIHf+7e9lj1Cxyq1u2TJEiV/94e9PY8++qiSGxsbg3r9tscAXHnllcq2jg7t2bp1q5JfeeUVJRs9Jm9VVqldM9PXbktLi0Et6T5d2qMvLCyUjRs3ypYtW2TAgAG+21NSUqSlpUUaGhqU+7vdbklJSQmqoUAoULuwKmoXXRVQR69pmhQWFsq6deukvLz8jKN8MzIyJCYmRsrKyny31dbWyoEDByQnJyc0LQa6gNqFVVG7CFZAX90XFBTIqlWrZMOGDRIXF+cb/3E6ndKrVy9xOp1y//33y5w5cyQxMVHi4+Nl9uzZkpOTc9YjP4HuQu3CqqhdBCugjv67cbaxY8cqt5eUlMi0adNEROTXv/61REdHy5QpU6S5uVny8vJk2bJlIWms1f32t79V8k033WRQSyJPJNTuzJkzu+21Dh8+rOR3331XyQ899JCSrXZusplEQu12J/055zfffLOS161b153N6RYBdfSdmVunZ8+esnTpUlm6dGmXGwWEGrULq6J2ESzmugcAwMbo6AEAsDGuR9+NampqlPz5558reejQod3ZHJjcd+Ov35k9e7aS77nnnpC+nv7aCceOHfOt/+Uvf1G26Y83qa6uDmlbgFC57bbblNx26l+RM/8O2xF79AAA2BgdPQAANsZX991o//79Sv7e975nUEtgBbt371byrFmzlPzJJ58o+dlnn1Xyueeeq+T169crefPmzUresGGDktubJx2wku3btytZP0Sqv4SyHbFHDwCAjdHRAwBgY3T0AADYWJTWmWmXupHX6xWn02l0M9AFHo/njOklIwm1a13ULrVrVZ2pXfboAQCwMTp6AABsjI4eAAAbo6MHAMDG6OgBALAxOnoAAGyMjh4AABujowcAwMbo6AEAsDE6egAAbMx0Hb3JZuRFACL9s4v0n9/KIv2zi/Sf38o689mZrqNvbGw0ugnookj/7CL957eySP/sIv3nt7LOfHamu6hNa2urHDx4UDRNE5fLJXV1dRF9sYlAeb1eSUtL69b3TdM0aWxslNTUVImONt3/jt2G2g0OtWscajc4Zq/dc7qlRQGIjo6WAQMGiNfrFRGR+Ph4Cq4Luvt948pX1G6oULvdj9oNDbPWbuT+CwsAQASgowcAwMZM29E7HA556qmnxOFwGN0US+F9Mx6fQdfwvhmPz6BrzP6+me5gPAAAEDqm3aMHAADBo6MHAMDG6OgBALAxOnoAAGyMjh4AABszbUe/dOlSGTRokPTs2VOys7Plk08+MbpJplFcXCyZmZkSFxcnSUlJMmnSJKmtrVXuc+LECSkoKJB+/fpJ3759ZcqUKeJ2uw1qcWShdttH7Zobtds+S9euZkKrV6/WYmNjtRUrVmifffaZNn36dC0hIUFzu91GN80U8vLytJKSEq26ulrbvXu3NmHCBM3lcmlHjx713WfGjBlaWlqaVlZWplVWVmojRozQRo4caWCrIwO16x+1a17Urn9Wrl1TdvRZWVlaQUGBL58+fVpLTU3ViouLDWyVeR0+fFgTEW3btm2apmlaQ0ODFhMTo61du9Z3n88//1wTEa2iosKoZkYEajcw1K55ULuBsVLtmu6r+5aWFqmqqpLc3FzfbdHR0ZKbmysVFRUGtsy8PB6PiIgkJiaKiEhVVZWcPHlSeQ+HDBkiLpeL9zCMqN3AUbvmQO0Gzkq1a7qO/siRI3L69GlJTk5Wbk9OTpb6+nqDWmVera2tUlRUJKNGjZJhw4aJiEh9fb3ExsZKQkKCcl/ew/CidgND7ZoHtRsYq9Wu6S5Ti8AUFBRIdXW17Nixw+imAAGhdmFVVqtd0+3Rn3feedKjR48zjlR0u92SkpJiUKvMqbCwUDZu3ChbtmyRAQMG+G5PSUmRlpYWaWhoUO7Pexhe1G7nUbvmQu12nhVr13QdfWxsrGRkZEhZWZnvttbWVikrK5OcnBwDW2YemqZJYWGhrFu3TsrLyyU9PV3ZnpGRITExMcp7WFtbKwcOHOA9DCNqt2PUrjlRux2zdO0aeihgO1avXq05HA6ttLRUq6mp0fLz87WEhAStvr7e6KaZwsyZMzWn06lt3bpVO3TokG85duyY7z4zZszQXC6XVl5erlVWVmo5OTlaTk6Oga2ODNSuf9SueVG7/lm5dk3Z0Wuapi1evFhzuVxabGyslpWVpe3cudPoJpmGiJx1KSkp8d3n+PHj2qxZs7Rzzz1X6927t3bLLbdohw4dMq7REYTabR+1a27UbvusXLtcjx4AABsz3Rg9AAAIHTp6AABsjI4eAAAbo6MHAMDG6OgBALAxOnoAAGyMjh4AABujowcAwMbo6AEAsDE6egAAbIyOHgAAG/s/3GTwpIqdkLUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: (60000, 784) (60000, 1)\n",
            "Test samples: (10000, 784) (10000, 1)\n",
            "Evaluation set: (100, 784)\n",
            "Train samples: (60000, 784) (60000,)\n",
            "Test samples: (100, 784) (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Learning with noisy labels\n",
        "\n",
        "To demonstrate the necessity of the adaptive approach, we simulate noisy data by introducing the common mistakes.\n",
        "For instance, we randomly change 3-->8, 8-->3, 1-->{4, 7}, 5-->6 etc.\n",
        "\n",
        "The amount of noise injected as a part of this stochastic process is controlled by the paramater **noise_probability** ($\\in [0, 1]$).\n"
      ],
      "metadata": {
        "id": "kP28ZG1s_R3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "noise_probability = 0.7\n",
        "\n",
        "def corrupt_label(y, err):\n",
        "    found = np.where(err == y)\n",
        "    if len(found) > 0:\n",
        "        # select an element at random (index != found)\n",
        "        noisy_label = random.choice(err)\n",
        "        while noisy_label == y:\n",
        "            noisy_label = random.choice(err)\n",
        "        return noisy_label\n",
        "    return y\n",
        "\n",
        "# We corrupt the MNIST data with some common mistakes, such as 3-->8, 8-->3, 1-->{4, 7}, 5-->6 etc.\n",
        "def corrupt_labels(y_train, noise_probability):\n",
        "    num_samples = y_train.shape[0]\n",
        "    err_es_1 = np.array([0, 2, 3, 5, 6, 8, 9])\n",
        "    err_es_2 = np.array([1, 4, 7])\n",
        "\n",
        "    corruptions = {}\n",
        "    corrupted_indexes = {}\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        p = random.random()\n",
        "\n",
        "        if p < noise_probability:\n",
        "            y = y_train[i]\n",
        "            y_noisy = corrupt_label(y, err_es_1)\n",
        "            if y_noisy == y:\n",
        "                y_noisy = corrupt_label(y, err_es_2)\n",
        "\n",
        "            key = str(y_train[i]) + '->' + str(y_noisy)\n",
        "            corrupted_indexes[i] = i\n",
        "\n",
        "            if key in corruptions:\n",
        "                corruptions[key] += 1\n",
        "            else:\n",
        "                corruptions[key] = 0\n",
        "\n",
        "            y_train[i] = y_noisy\n",
        "\n",
        "    return corruptions, corrupted_indexes\n",
        "\n",
        "corruptions, corrupted_indexes = corrupt_labels(y_train, noise_probability)\n",
        "print (\"Corruptions: \" + str(corruptions))\n",
        "print (\"Corrupted indexes: {}\".format(list(corrupted_indexes.keys())[0:10]))\n"
      ],
      "metadata": {
        "id": "_gQF7tFB-7qr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee3c2beb-de8c-4a10-8ab2-9e0afdc03d7e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corruptions: {'5->8': 658, '0->3': 694, '4->2': 645, '9->2': 739, '1->6': 692, '4->8': 548, '3->5': 720, '6->3': 709, '7->9': 620, '2->6': 686, '8->6': 695, '6->8': 714, '9->3': 699, '4->6': 567, '1->0': 675, '2->0': 751, '2->5': 700, '3->0': 722, '9->0': 688, '0->9': 654, '5->2': 639, '0->5': 724, '6->0': 718, '1->5': 645, '8->3': 761, '7->5': 624, '9->8': 675, '9->6': 732, '3->2': 737, '7->0': 609, '4->3': 570, '8->2': 684, '1->9': 672, '4->0': 587, '6->5': 694, '0->2': 704, '4->5': 571, '5->3': 641, '1->8': 732, '7->2': 656, '0->6': 675, '2->3': 677, '3->8': 699, '4->9': 622, '6->2': 688, '7->8': 595, '8->5': 657, '7->6': 629, '1->3': 661, '3->9': 736, '2->8': 681, '3->6': 704, '2->9': 658, '8->9': 639, '6->9': 694, '1->2': 700, '9->5': 668, '5->9': 618, '5->6': 648, '5->0': 646, '7->3': 668, '0->8': 667, '8->0': 692}\n",
            "Corrupted indexes: [0, 1, 2, 4, 8, 9, 12, 13, 15, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Standard K-NN on this noisy data\n",
        "\n",
        "We now execute static k-NN on this noisy data. The effectiveness of the classifier is very poor (for your own understanding, try to see why; note that answering this is not an actionable item and hence isn't graded)."
      ],
      "metadata": {
        "id": "4QxFM4BK_cUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = 3\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier(n_neighbors=K)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "print (\"{}-NN model fitted\".format(K))\n",
        "\n",
        "y_preds = model.predict(x_test)\n",
        "print (\"K-NN model accuracy with k={}: {:.4f}\".format(K, accuracy_score(y_test, y_preds)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8SaJ0Wf_c6-",
        "outputId": "932a987e-ede9-4896-aa9e-6c2af8cc7409"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3-NN model fitted\n",
            "K-NN model accuracy with k=3: 0.2700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now would implement a simple unsupervised (heuristic-based) method to predict if we need a large or a small value of $k$ for a correct classification. Recall from the lecture notes that a dense neighborhood perhaps would be better served with a large value of $k$, whereas a relatively less compact neighborhood may do well with a small $k$. A sample function to estimate the quality of a neighborhood is the variance of the distances of the neighborhood points, i.e.,\n",
        "\n",
        "$$\\phi(N_k(\\mathbf{x})) = \\sum_{z \\in N_k(\\mathbf{x})} (d(\\mathbf{x},\\mathbf{z}) - \\mu)^2, \\text{where}\\,\\,\\,\\,\\mu=\\sum_{z \\in N_k(\\mathbf{x})} d(\\mathbf{x},\\mathbf{z}).$$\n",
        "\n",
        "Notations:\n",
        " * $\\mathbf{x}$: A data instance for inference.\n",
        " * $N_k(\\mathbf{x})$: A neighborhood of size $k$ around the data instance for inference.\n",
        " * $d(\\mathbf{x},\\mathbf{z})$: Distance (Euclidean or cosine or any other) between the test point $\\mathbf{x}$ and a training point $\\mathbf{z}$.\n",
        " * $\\mu$: The average of the distances of the neighboring training points from the test point.   \n",
        "\n",
        "\n",
        "Again for your own understanding, try to see wheether it makes sense to argue that the higher the variance, the less compact is the neighborhood, and perhaps we want a smaller $k$ for such ones? (no actionable item and no grading for finding this answer)\n",
        "\n",
        "Our task is now to write the function *predict_k_values_unsupervised*."
      ],
      "metadata": {
        "id": "D8iY-JKl_ib8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Takes the test set and an index of nearest neighbors.\n",
        "# Iterates over each point, computes the variance of distances, scales that into the range [1, MAX_K]\n",
        "# and returns a list of adaptively chosen K values (one for each instance).\n",
        "def predict_k_values_unsupervised(x_test, nn_index):\n",
        "    n = x_test.shape[0]\n",
        "    variances = []\n",
        "    for i in range(n):\n",
        "        x = x_test[i]\n",
        "        distances, ids = nn_index.kneighbors([x], return_distance=True)\n",
        "        variances.append(np.var(distances))\n",
        "\n",
        "    min_v = min(variances)\n",
        "    max_v = max(variances)\n",
        "\n",
        "    k_values = [1 + math.floor((MAX_K-1) * (float(var) - min_v)/(max_v - min_v)) for var in variances]\n",
        "    return k_values"
      ],
      "metadata": {
        "id": "MZtwR_27_sKH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For adaptively choosing $k$ we need to set an upper bound (the lower bound being 1).\n",
        "MAX_K = 20\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def adaptive_knn(x_test, y_test):\n",
        "\n",
        "    # Build the index so that we retrieve the neighborhoods faster\n",
        "    nn_index = NearestNeighbors(n_neighbors=MAX_K).fit(x_train)\n",
        "\n",
        "    print (\"{}-NN index built\".format(MAX_K))\n",
        "\n",
        "    # Dynamic k workflow\n",
        "    k_values = predict_k_values_unsupervised(x_test, nn_index)\n",
        "    y_preds = []\n",
        "\n",
        "    for i in range(len(x_test)):\n",
        "        k = k_values[i]\n",
        "\n",
        "        #print (\"Predicting with nn-size = {}\".format(k))\n",
        "        x = x_test[i]\n",
        "        distances, ids = nn_index.kneighbors([x])\n",
        "        ids = ids.flatten()\n",
        "\n",
        "        ids = ids[:k] # take the first k (out of MAX_K)\n",
        "        nn_labels = []\n",
        "        for x_id in ids:\n",
        "            nn_labels.append(y_train[x_id])\n",
        "\n",
        "        y_pred = max(set(nn_labels), key=nn_labels.count)\n",
        "        y_preds.append(y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_preds)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "0gAwOBwO_tc6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A7qOhFSuYh3u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = adaptive_knn(x_test, y_test)\n",
        "print (\"Adaptive K-NN model accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "h7qLhANG_ylT",
        "outputId": "0124562c-f07b-492c-9391-b87852470e0b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20-NN index built\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-bb960b6f5f16>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaptive_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Adaptive K-NN model accuracy: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-3060c7954d77>\u001b[0m in \u001b[0;36madaptive_knn\u001b[0;34m(x_test, y_test)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print (\"Predicting with nn-size = {}\".format(k))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    822\u001b[0m         )\n\u001b[1;32m    823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_pairwise_distances_reductions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             results = ArgKmin.compute(\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             return ArgKmin32.compute(\n\u001b[0m\u001b[1;32m    290\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\u001b[0m in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_original_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZaSlSDtvcKpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tasks: Investigate if we can do better than the heuristics.\n",
        "\n",
        "We now seek to learn a function of the form $\\theta: \\mathbf{x} \\mapsto \\mathbb{Z}_k$ (e.g., via $k$-class softmax regression or an SVM or any other parametric classifier).\n",
        "\n",
        "**Task 1 (30 marks)**: Replace the function *predict_k_values_unsupervised* with another function *predict_k_values_supervised* which will do the following:\n",
        "- Learn a mapping between a data instance from the training set and the smallest value of $k$ that results in correct predictions for that instance. In your report, clearly describe how do you train this classifier (e.g., what are the ground-truth y values for each training data point $\\mathbf{x} \\in S_{train}$.    \n",
        "- Apply this paramateric model to *predict* the value of $k$ at inference time (for this you just need to replace the call to **predict_k_values_unsupervised** inside **adaptive_knn** with your implemented method).\n",
        "\n",
        "**Task 2 (30 marks)**: Compare the performance of your implemented supervised approach vs. the baseline (unsupervised one) for different simulated datasets with varying amounts of noise. Make a plot with *noise_probability* on the x-axis and accuracy on the y-axis for 11 different values - {0, 0.1, ... 0.9, 1}.\n",
        "\n",
        "**Task 3 (40 marks)**: Write a commentary on the observations reflecting on your approach (e.g., on the assumptions you make, on the hyper-parameter choices for your method etc.) and figuring out **when and why it works** (e.g., for what hyper-parameter settings), and **when and why it doesn't**.\n",
        "  - 3(a): Clear description of the assumptions, the experiment settings (e.g., different levels of noises) and hyper-parameters of your approach (e.g., learning rate or regularisation constant of softmax regression) (10 marks).\n",
        "  - 3(b): Sensitivity analysis of the hyper-parameters (ideally should be demonsrated with plots of results) (15 marks).\n",
        "  - 3(c): Your observations and conclusions on per-instance error analysis, e.g., what happens in different types (different levels of compactness or homogeneity) of neighborhoods (15 marks).\n"
      ],
      "metadata": {
        "id": "WIsAcfjE_2yU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "*Task 1: *\n",
        "\n",
        "- gen_k_vals is a function that finds the minimuk value of k for each x instance that will result in a correct prediction of y\n",
        "- it is quite slow... not ideal\n",
        "- however, as we are creating a supervised approach, we need to create a training dataset for the k values\n",
        "- it feels inefficient to do this sort of this when the true values won't actually be used, instead a model predicting the values will be used. HOWEVER, obviosuly it does make sense as we want our model to generalise outside of the training and test data"
      ],
      "metadata": {
        "id": "O85LUfcWykL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retry: Finding k truth values\n",
        "\n",
        "# For adaptively choosing $k$ we need to set an upper bound (the lower bound being 1).\n",
        "MAX_K = 20\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def gen_k_vals(x_test, y_test):\n",
        "\n",
        "    # Build the index so that we retrieve the neighborhoods faster\n",
        "    nn_index = NearestNeighbors(n_neighbors=MAX_K).fit(x_train)\n",
        "\n",
        "    print (\"{}-NN index built\".format(MAX_K))\n",
        "    k_values = []\n",
        "\n",
        "    for i in range(len(x_test)):\n",
        "        if (i%100)==0:\n",
        "          print(\"x value\", i)\n",
        "        k = 0\n",
        "        correct = False\n",
        "\n",
        "        x = x_test[i]\n",
        "        y = y_test[i]\n",
        "\n",
        "        #print (\"Predicting with nn-size = {}\".format(k))\n",
        "        distances, ids = nn_index.kneighbors([x])\n",
        "        ids = ids.flatten()\n",
        "\n",
        "        ids = ids[:MAX_K] # take the first k (out of MAX_K)\n",
        "        nn_labels = []\n",
        "        for x_id in ids:\n",
        "            nn_labels.append(y_train[x_id])\n",
        "\n",
        "        while not correct and k<MAX_K:\n",
        "          k += 1\n",
        "          y_pred = max(set(nn_labels[:k]), key=nn_labels[:k].count)\n",
        "          correct = (y_pred == y)\n",
        "        print(k)\n",
        "\n",
        "        k_values.append(k)\n",
        "    return k_values"
      ],
      "metadata": {
        "id": "E5PCvZPPYi2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The code is too slow to generate k_train from all of the training data\n",
        "k_test = gen_k_vals(x_test, y_test)\n",
        "print(k_test)"
      ],
      "metadata": {
        "id": "xiFKeoWgcLmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How can we create k_train if the nearest neighbour model is fitted using k_train? It is producing 1 nearest neighbour and all are having the correct classification. only one result for k. We need to investigate why this is....\n"
      ],
      "metadata": {
        "id": "g6rE0ZRoAoBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Attempt 1\n",
        "\n",
        "- Use a multinomial logistic regression model with the data\n",
        "- Accuracy not any better than the naive method\n",
        "- HOWEVER: we only used 10% of our training set to train the model. It is not a fair comparison?"
      ],
      "metadata": {
        "id": "sw6MRVUDz-Mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# fit a model using x_train and k_train\n",
        "# model chosen multinomial logistic regression model\n",
        "def predict_k_values_supervised(x_test):\n",
        "\n",
        "  lr_model = LogisticRegression(multi_class='multinomial')\n",
        "  lr_model.fit(x_train[:6000], k_train)\n",
        "\n",
        "  # Predict k values for the test set\n",
        "  k_pred = lr_model.predict(x_test)\n",
        "\n",
        "  # Print or use the predicted k values as needed\n",
        "  return(k_pred)\n"
      ],
      "metadata": {
        "id": "pT2wXGS-pFqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For adaptively choosing $k$ we need to set an upper bound (the lower bound being 1).\n",
        "MAX_K = 20\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def adaptive_knn_v1(x_test, y_test):\n",
        "\n",
        "    # Build the index so that we retrieve the neighborhoods faster\n",
        "    nn_index = NearestNeighbors(n_neighbors=MAX_K).fit(x_train)\n",
        "\n",
        "    print (\"{}-NN index built\".format(MAX_K))\n",
        "\n",
        "    # Dynamic k workflow\n",
        "    k_values = predict_k_values_supervised(x_test)\n",
        "    y_preds = []\n",
        "\n",
        "    for i in range(len(x_test)):\n",
        "        k = k_values[i]\n",
        "\n",
        "        #print (\"Predicting with nn-size = {}\".format(k))\n",
        "        x = x_test[i]\n",
        "        distances, ids = nn_index.kneighbors([x])\n",
        "        ids = ids.flatten()\n",
        "\n",
        "        ids = ids[:k] # take the first k (out of MAX_K)\n",
        "        nn_labels = []\n",
        "        for x_id in ids:\n",
        "            nn_labels.append(y_train[x_id])\n",
        "\n",
        "        y_pred = max(set(nn_labels), key=nn_labels.count)\n",
        "        y_preds.append(y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_preds)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "NhT8Z7zKv2b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = adaptive_knn_v1(x_test, y_test)\n",
        "print (\"Adaptive K-NN model accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "id": "qIlDzNjBwAam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "unique_classes_train = np.unique(k_train)\n",
        "print(\"Unique classes in k_train:\", unique_classes_train)\n",
        "print(k_train)"
      ],
      "metadata": {
        "id": "BPGCRnRw_kb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "JXjIrMT64K_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Attempt 2\n",
        "\n",
        "Use a SVM model with the data"
      ],
      "metadata": {
        "id": "ALo_8_p61kjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "def predict_k_values_supervised(x_test):\n",
        "  svc_model = SVC(C=1000, kernel='linear')\n",
        "  svc_model.fit(x_train, k_train)\n",
        "\n",
        "  # Predict k values for the test set\n",
        "  k_pred = svc_model.predict(x_test)\n",
        "  return k_pred"
      ],
      "metadata": {
        "id": "GkFRmd8m2Qda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = adaptive_knn(x_test, y_test)\n",
        "print (\"Adaptive K-NN model accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "id": "n4_hqwBk2uZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_k_ground_truth(x_test, y_test, x_train, y_train, subsample_fraction = 0.1):\n",
        "  # Use a subsample of the training data to build the k-NN index\n",
        "    subsample_size = int(len(x_train) * subsample_fraction)\n",
        "    subsample_indices = np.random.choice(len(x_train), subsample_size, replace=False)\n",
        "    x_train_subsample = x_train[subsample_indices]\n",
        "    y_train_subsample = y_train[subsample_indices]\n",
        "    nn_index = NearestNeighbors(n_neighbors=len(x_train_subsample)).fit(x_train_subsample)\n",
        "\n",
        "    print(\"{}-NN index built with a subsample of {} training instances\".format(len(x_train_subsample), subsample_size))\n",
        "\n",
        "    subsample_size = int(len(x_test) * subsample_fraction)\n",
        "    subsample_indices = np.random.choice(len(x_test), 0.4, replace=False)\n",
        "    x_test_subsample = x_test[subsample_indices]\n",
        "    y_test_subsample = y_test[subsample_indices]\n",
        "\n",
        "    k_values = []\n",
        "    print(len(x_test_subsample))\n",
        "\n",
        "    for i in range(len(x_test_subsample)):\n",
        "\n",
        "\n",
        "        x = x_test_subsample[i]\n",
        "        y = y_test_subsample[i]\n",
        "\n",
        "        distances, ids = nn_index.kneighbors([x])\n",
        "        ids = ids.flatten()\n",
        "\n",
        "        ids = ids[:len(x_train_subsample)]  # take the first k (out of the subsample)\n",
        "        nn_labels = [y_train_subsample[x_id] for x_id in ids]\n",
        "\n",
        "        k = 1\n",
        "        while k < MAX_K:\n",
        "            y_pred = max(set(nn_labels[:k]), key=nn_labels[:k].count)\n",
        "            if y_pred == y:\n",
        "                break\n",
        "            k += 1\n",
        "        if (i % 100) == 0:\n",
        "            print(\"x value\", i)\n",
        "            print(k)\n",
        "        k_values.append(k)\n",
        "\n",
        "    return k_values\n"
      ],
      "metadata": {
        "id": "bfjAqxKz_1mj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_vals = gen_k_ground_truth(x_test, y_test, x_train, y_train )\n",
        "print(k_vals)"
      ],
      "metadata": {
        "id": "ERIr5ZL5ATUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_train_k, x_test_k, k_train_k, k_test_k = train_test_split(x_test, k_vals, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a logistic regression classifier\n",
        "classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
        "classifier.fit(x_train_k, k_train_k)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D-51TCT6DjWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# create subsamples of x_train and y_train for creating ground truth values of k\n",
        "\n",
        "x_train_sub, x_test_sub, y_train_sub, y_test_sub = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)\n",
        "\n",
        "k_vals = gen_k_ground_truth(x_test_sub, y_test_sub, x_train_sub, y_train_sub)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "--4V9vDpIZyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_k, x_test_k, k_train_k, k_test_k = train_test_split(x_test_sub, k_vals, test_size=0.2, random_state=42)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train a logistic regression classifier\n",
        "classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
        "classifier.fit(x_train_k, k_train_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "OMRXrnLJJsMg",
        "outputId": "5e86aaff-77cd-4862-d92c-006db661c8d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_k_values_unsupervised(x_test):\n",
        "  # Train a logistic regression classifier\n",
        "  classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
        "  classifier.fit(x_train_k, k_train_k)\n",
        "  # Predict k values for the test set\n",
        "  k_pred = classifier.predict(x_test)\n",
        "\n",
        "  # Print or use the predicted k values as needed\n",
        "  return(k_pred)\n",
        "\n",
        "k_vals_LR_pred = predict_k_values_unsupervised(x_test)"
      ],
      "metadata": {
        "id": "JQUf2Z0cJPpy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For adaptively choosing $k$ we need to set an upper bound (the lower bound being 1).\n",
        "MAX_K = 20\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def adaptive_knn_v1(x_test, y_test):\n",
        "\n",
        "    # Build the index so that we retrieve the neighborhoods faster\n",
        "    nn_index = NearestNeighbors(n_neighbors=MAX_K).fit(x_train)\n",
        "\n",
        "    print (\"{}-NN index built\".format(MAX_K))\n",
        "\n",
        "    # Dynamic k workflow\n",
        "    k_values = k_vals_LR_pred\n",
        "    y_preds = []\n",
        "\n",
        "    for i in range(len(x_test)):\n",
        "        k = k_values[i]\n",
        "\n",
        "        #print (\"Predicting with nn-size = {}\".format(k))\n",
        "        x = x_test[i]\n",
        "        distances, ids = nn_index.kneighbors([x])\n",
        "        ids = ids.flatten()\n",
        "\n",
        "        ids = ids[:k] # take the first k (out of MAX_K)\n",
        "        nn_labels = []\n",
        "        for x_id in ids:\n",
        "            nn_labels.append(y_train[x_id])\n",
        "\n",
        "        y_pred = max(set(nn_labels), key=nn_labels.count)\n",
        "        y_preds.append(y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_preds)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "_z-60VGV43vd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = adaptive_knn_v1(x_test, y_test)\n",
        "print (\"Adaptive K-NN model accuracy: {:.4f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oD6Xu315AIW",
        "outputId": "a33174f4-cdf3-4c53-9607-f0fc0c6e49d1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20-NN index built\n",
            "Adaptive K-NN model accuracy: 0.5400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model works!!!!"
      ],
      "metadata": {
        "id": "sjHg_I1F5fyo"
      }
    }
  ]
}